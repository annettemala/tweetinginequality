---
title: "Tweet analysis"
author: "Annette Malapally"
date: "21 Januar 2022"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
#library(groundhog)
#pkgs <- c("psych", "dplyr", "haven", "summarytools", "Hmisc", "rstatix", "rcompanion", "jtools", "tidyr",
#          "rms", "esquisse", "tibble", "apaTables", "DescTools", "car", "lmtest", "robustbase", "psycl", "countreg",
#          "ggcorrplot", "knitr")
#groundhog.library(pkgs, "2022-04-11")

library(psych)
library(dplyr)
library(haven)
library(summarytools)
library(Hmisc)
library(rstatix)
library(rcompanion)
library(jtools)
library(tidyr)
library(rms)
library(esquisse)
library(tibble)
library(apaTables)
library(DescTools)
library(car)
library(lmtest)
library(robustbase)
library(pscl)
library(countreg)
library(ggcorrplot)
library(knitr)
```

# Prepare data
## Load data
```{r}
# Loading data
data <- read_sav("tweets_race.sav")

# Choose only data where syntax and ML frame match
out <- subset(data, data$MLframe != data$frame)
data <- subset(data, data$MLframe == data$frame)

# Covert empty strings to NA
data <- data %>% mutate_all(na_if,"")
```

## Recode variable
```{r}
# Create numeric frame variable
data$frame_num <- as.factor(paste(ifelse(data$MLframe == 'disadvantage frame', 1, 0)))
```

# Describe data
## Followers count
```{r}
kable(psych::describe(data$followerscount))
```

## Histogram of followers
###All users
```{r}
plotNormalHistogram(data$followerscount)
```

https://techjury.net/blog/twitter-statistics/#gref Examining nearly 100 million Twitter accounts, Brandwatch found that the average number of followers those accounts have is 707. If we want to keep Twitter analytics free of celebrity bias and choose to ignore accounts that have over 100,000 followers, the average user has 453 people following them. \ 

## Tweet metrics
### Retweets
```{r}
kable(psych::describe(data$retweetcount))
plotNormalHistogram(data$retweetcount)
```

###Replies
```{r}
kable(psych::describe(data$replycount))
plotNormalHistogram(data$replycount)
```

###Quotes
```{r}
kable(psych::describe(data$quotecount))
plotNormalHistogram(data$quotecount)
```

###Likes
```{r}
kable(psych::describe(data$likecount))
plotNormalHistogram(data$likecount)
```

## Log transform of variables
### Check for linear relationships
```{r}
data %>% 
  ggplot(aes(x = followerscount, y = likecount)) +
  geom_point(alpha = .2) +
  geom_smooth() +
  geom_smooth(method = "lm", colour = "red") # linear relationship

data %>%
  ggplot(aes(x = followerscount, y = likecount)) +
  geom_point(alpha = .2) +
  geom_smooth() +
  geom_smooth(method = "lm", colour = "red") + 
  scale_x_continuous(trans = "log1p") +
  scale_y_continuous(trans = "log1p") 

data %>% 
  ggplot(aes(x = replycount, y = quotecount)) +
  geom_point(alpha = .2) +
  geom_smooth() +
  geom_smooth(method = "lm", colour = "red") # linear relationship

data %>%
  ggplot(aes(x = replycount, y = quotecount)) +
  geom_point(alpha = .2) +
  geom_smooth() +
  geom_smooth(method = "lm", colour = "red") + 
  scale_x_continuous(trans = "log1p") +
  scale_y_continuous(trans = "log1p") 
```


### Transform data
To deal with skew in our data, and to achieve linearity, we log transform followerscount, and tweets metrics to compute correlations. 
```{r}
# Followers count
data$followerscount_log <- data$followerscount %>% log1p() # log1p() instead of log() because there are zeroes in the data
data %>% ggplot(aes(x = followerscount_log)) + geom_histogram()

# Like count
data$likecount_log <- data$likecount %>% log1p() 

# Retweet count
data$retweetcount_log <- data$retweetcount %>% log1p() 

# Quote count
data$quotecount_log <- data$quotecount %>% log1p() 

# Reply count
data$replycount_log <- data$replycount %>% log1p() 
```


## Correlation of followers count with tweet metrics
We adjusted the p-values using the Bonferroni method.
```{r}
corr_tab_followers <- psych::corr.test(as.matrix(data[c('likecount_log', 'retweetcount_log', 'quotecount_log', 'replycount_log', "followerscount_log")]), method = "pearson", adjust = 'bonferroni', ci = TRUE)
kable(print(corr_tab_followers, digits=4, short = FALSE))
apa.cor.table(dplyr::select(data, c(likecount_log:replycount_log)), show.conf.interval = TRUE)
```

### Does time of posting correlate with tweet metrics?
```{r}
# Time delta
data$date_day <- as.Date(substr(data$date, 1, 10))
data$age <- as.numeric(difftime(as.Date("2022-03-17"), data$date_day))

# Distribution of age
data %>% ggplot(aes(x = age)) + geom_histogram()

# Correlation of age with tweet metrics
corr_tab_age <- psych::corr.test(as.matrix(data[c('age', 'likecount_log', 'retweetcount_log', 'quotecount_log', 'replycount_log')]), method = "pearson", adjust = 'bonferroni', ci = TRUE)
kable(print(corr_tab_age, digits=4, short = FALSE))
```

# Prevalence of tweets
## Descriptive analysis
```{r}
table_frames <- summarytools::freq(data$MLframe, plain.ascii = FALSE, style = "rmarkdown")
kable(table_frames)

# Corrected prevalence of privilege frames
table_frames_corr <- enframe(table_frames)[0:2,]
table_frames_corr$value_corr <- ifelse(table_frames_corr$name == 'privilege frame', 
                                       table_frames_corr$value*4.7, table_frames_corr$value)
prev_df <- table_frames_corr$value_corr[table_frames_corr$name == 'disadvantage frame']
prev_pf <- table_frames_corr$value_corr[table_frames_corr$name == 'privilege frame']
total <- prev_df+prev_pf
prev_df <- prev_df/(total)
prev_pf <- prev_pf/(total)
prev_df
prev_pf
```

# Inspection of zero-values
```{r}
# Make sure tweet metrics don't have missing values
sum(is.na(data[c('retweetcount', 'replycount', 'quotecount', 'likecount')]))

# Function to recode variables
recode_metrics <- function(metric){
  metric <- ifelse(metric == 0, 0, 1)
  return (metric)
}

# Recode tweet metrics
data$retweet_dicho <- recode_metrics(data$retweetcount)
data$reply_dicho <- recode_metrics(data$replycount)
data$quote_dicho <- recode_metrics(data$quotecount)
data$like_dicho <- recode_metrics(data$likecount)

# Distribution of dichotomous variables
kable(summarytools::freq(data$retweet_dicho, plain.ascii = FALSE, style = "rmarkdown"))
kable(summarytools::freq(data$reply_dicho, plain.ascii = FALSE, style = "rmarkdown"))
kable(summarytools::freq(data$quote_dicho, plain.ascii = FALSE, style = "rmarkdown"))
kable(summarytools::freq(data$like_dicho, plain.ascii = FALSE, style = "rmarkdown"))
```

## Poisson regression of tweet metrics on frame
### Visualization
We plot added variable plots (partial regression plots) which show the relationship between the outcome variable and one predictor variable while controlling for the presence of other predictor variables in the model. 
```{r}
data %>%
  pivot_longer(cols = retweetcount:quotecount, names_to = "column") %>%
  ggplot(aes(x = column, y = value, group = frame, colour = frame)) +
  stat_summary(fun = mean, geom = "point", na.rm = TRUE, position = position_dodge(width=0.5)) +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = .3, position = position_dodge(width=0.5)) +
  theme_apa() +
  labs(title = "Mean tweet reactions across frames with 95% CI",
       x = "",
       y = "Tweet reactions")

plot <- last_plot()
ggplot_to_ppt(gg="plot")

tweetmetrics_tab <- data %>%
                    group_by(MLframe) %>%
                    get_summary_stats(retweetcount, 
                                      replycount, 
                                      quotecount, 
                                      likecount,
                                      type = "mean_se")

kable(tweetmetrics_tab)
```

### Retweet count
-**Count regression of retweet counts**
Interpretation of rootograms: The under hanging values (e.g.) for 0 indicate that there are too few (e.g.) zeros expected in the respective model. The over hanging values show that there is overprediction for the respective values. 
```{r}
# Poisson regression
poisson_retweets <- glm(retweetcount ~ followerscount + frame_num, family="poisson", data=data)
summary(poisson_retweets)
confint(poisson_retweets)
countreg::rootogram(poisson_retweets)

# Poisson regression (followers count log transformed)
poisson_retweets <- glm(retweetcount ~ followerscount_log + frame_num, family="poisson", data=data)
summary(poisson_retweets)
confint(poisson_retweets)
countreg::rootogram(poisson_retweets)
```

### Reply count
-**Count regression of retweet counts**
```{r}
# Poisson regression
poisson_replies <- glm(replycount ~ followerscount + frame_num, family="poisson", data=data)
summary(poisson_replies)
confint(poisson_replies)
countreg::rootogram(poisson_replies)

# Poisson regression (followers count log transformed)
poisson_replies <- glm(replycount ~ followerscount_log + frame_num, family="poisson", data=data)
summary(poisson_replies)
confint(poisson_replies)
countreg::rootogram(poisson_replies)
```

### Quote count
-**Count regression of retweet counts**
```{r}
# Poisson regression
poisson_quotes <- glm(quotecount ~ followerscount + frame_num, family="poisson", data=data)
summary(poisson_quotes)
confint(poisson_quotes)
countreg::rootogram(poisson_quotes)

# Poisson regression (followers count log transformed)
poisson_quotes <- glm(quotecount ~ followerscount_log + frame_num, family="poisson", data=data)
summary(poisson_quotes)
confint(poisson_quotes)
countreg::rootogram(poisson_quotes)
```

### Like count
-**Count regression of retweet counts**
```{r}
# Poisson regression
poisson_likes <- glm(likecount ~ followerscount + frame_num, family="poisson", data=data)
summary(poisson_likes)
confint(poisson_likes)
countreg::rootogram(poisson_likes)

# Poisson regression (followers count log transformed)
poisson_likes <- glm(likecount ~ followerscount_log + frame_num, family="poisson", data=data)
summary(poisson_likes)
confint(poisson_likes)
countreg::rootogram(poisson_likes)
```

# Topic distribution per frame
## Table of topics per frame
```{r}
topics_overall <- data %>%
              get_summary_stats(topic_race1, 
                                topic_race2,
                                topic_race4, 
                                topic_race6,
                                type = "mean_se")

kable(topics_overall)

topics_tab <- data %>%
              group_by(MLframe) %>%
              get_summary_stats(topic_race1, 
                                topic_race2,
                                topic_race4, 
                                topic_race6,
                                type = "mean_se")
kable(topics_tab)
```

## Visualization
```{r}
data %>%
  pivot_longer(cols = c(topic_race1, topic_race2, topic_race4, topic_race6), names_to = "column") %>%
  ggplot(aes(x = column, y = value, group = frame, shape = MLframe)) +
  stat_summary(fun = mean, geom = "point", na.rm = TRUE, position = position_dodge(width=0.5)) +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = .3, position = position_dodge(width=0.5)) +
  expand_limits(y=0) +
  theme_apa() +
  labs(title = "Mean topic strength across frames with 95% CI",
       x = "",
       y = "Topic strength")

plot <- last_plot()
ggplot_to_ppt(gg="plot")
```

## Statistical differences in topic use 
### MANOVA
```{r}
# Choose topics
topics_columns = cbind(data$topic_race1,
                       data$topic_race2,
                       data$topic_race4,
                       data$topic_race6)
topics_string = c('topic_race1', 
                  'topic_race2',
                  'topic_race4',  
                  'topic_race6',
                  'MLframe')

# Run MANOVA
res.man <- manova(topics_columns ~ MLframe, data = data)
summary(res.man, tol = 0)
```

### Post-hoc tests
Welch-test: when variances are not equal, or sample sizes are different across groups. 
```{r}
# To long format
data_long <- data[topics_string] %>%
             pivot_longer(-(MLframe), names_to = "variables", values_to = "value")

# Equal variances
var.test <- data_long %>%
            group_by(variables) %>%
            levene_test(value ~ MLframe)
kable(var.test)

# Multiple t-tests
stat.test <- data_long %>%
            group_by(variables) %>%
            t_test(value ~ MLframe, var.equal = FALSE) %>%
            adjust_pvalue(method = "holm") %>%
            add_significance() 

kable(stat.test)

# Effect sizes
eff_sizes <- data_long %>%
             group_by(variables) %>%
             cohens_d(value ~ MLframe, var.equal = FALSE)

kable(eff_sizes)
```

